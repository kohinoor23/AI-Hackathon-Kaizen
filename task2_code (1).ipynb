{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":72549,"databundleVersionId":7959527,"sourceType":"competition"},{"sourceId":7866114,"sourceType":"datasetVersion","datasetId":4614925},{"sourceId":7866179,"sourceType":"datasetVersion","datasetId":4614974}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-17T10:14:18.676260Z","iopub.execute_input":"2024-03-17T10:14:18.676641Z","iopub.status.idle":"2024-03-17T10:14:18.687851Z","shell.execute_reply.started":"2024-03-17T10:14:18.676610Z","shell.execute_reply":"2024-03-17T10:14:18.686931Z"},"trusted":true},"execution_count":119,"outputs":[{"name":"stdout","text":"/kaggle/input/ai-for-social-good-aries-iitd-x-kaizen-24/Public/submission_format.csv\n/kaggle/input/ai-for-social-good-aries-iitd-x-kaizen-24/Public/Task 1/dev.csv\n/kaggle/input/ai-for-social-good-aries-iitd-x-kaizen-24/Public/Task 1/train.csv\n/kaggle/input/ai-for-social-good-aries-iitd-x-kaizen-24/Public/Task 1/test.csv\n/kaggle/input/ai-for-social-good-aries-iitd-x-kaizen-24/Public/Task 2/dev.csv\n/kaggle/input/ai-for-social-good-aries-iitd-x-kaizen-24/Public/Task 2/train.csv\n/kaggle/input/ai-for-social-good-aries-iitd-x-kaizen-24/Public/Task 2/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:14:21.798470Z","iopub.execute_input":"2024-03-17T10:14:21.799168Z","iopub.status.idle":"2024-03-17T10:14:21.803383Z","shell.execute_reply.started":"2024-03-17T10:14:21.799133Z","shell.execute_reply":"2024-03-17T10:14:21.802444Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/ai-for-social-good-aries-iitd-x-kaizen-24/Public/Task 1/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:14:22.230699Z","iopub.execute_input":"2024-03-17T10:14:22.231013Z","iopub.status.idle":"2024-03-17T10:14:22.263609Z","shell.execute_reply.started":"2024-03-17T10:14:22.230989Z","shell.execute_reply":"2024-03-17T10:14:22.262808Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:14:23.250779Z","iopub.execute_input":"2024-03-17T10:14:23.251120Z","iopub.status.idle":"2024-03-17T10:14:23.260902Z","shell.execute_reply.started":"2024-03-17T10:14:23.251094Z","shell.execute_reply":"2024-03-17T10:14:23.259813Z"},"trusted":true},"execution_count":122,"outputs":[{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"                                          tweet_text  claim\n0  Coronavirus may have originated in lab linked ...      1\n1  @SCMPNews China will buy all shares that's y i...      1\n2  I'm curious if the pneumonia vaccine (Prevnar-...      1\n3  dear you knew about covid 19 in january it is ...      1\n4  Wow, they're as dumb as @realDonaldTrump sugge...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_text</th>\n      <th>claim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Coronavirus may have originated in lab linked ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@SCMPNews China will buy all shares that's y i...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I'm curious if the pneumonia vaccine (Prevnar-...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dear you knew about covid 19 in january it is ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wow, they're as dumb as @realDonaldTrump sugge...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train.describe()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:14:26.720752Z","iopub.execute_input":"2024-03-17T10:14:26.721097Z","iopub.status.idle":"2024-03-17T10:14:26.736366Z","shell.execute_reply.started":"2024-03-17T10:14:26.721071Z","shell.execute_reply":"2024-03-17T10:14:26.735103Z"},"trusted":true},"execution_count":123,"outputs":[{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"             claim\ncount  6986.000000\nmean      0.874034\nstd       0.331835\nmin       0.000000\n25%       1.000000\n50%       1.000000\n75%       1.000000\nmax       1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>claim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6986.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.874034</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.331835</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We observe that the data is skewed towards claim=1. So, we first sample a balanced data.","metadata":{}},{"cell_type":"code","source":"# Separate the data into positive and negative examples based on the target variable\npositive_examples = df_train[df_train['claim'] == 1]\nnegative_examples = df_train[df_train['claim'] == 0]\n\nmin_count = min(len(positive_examples), len(negative_examples))\n\n# Sample 50% of the positive examples\npositive_sampled = positive_examples.sample(n=min_count, random_state=42)\n\n# Sample 50% of the negative examples\nnegative_sampled = negative_examples.sample(n=min_count, random_state=42)\n\n# Concatenate the sampled data back together\nbalanced_df_train = pd.concat([positive_sampled, negative_sampled])\n\n# Shuffle the DataFrame to randomize the order of samples\nbalanced_df_train = balanced_df_train.sample(frac=1, random_state=42).reset_index(drop=True)\n\n# Check the distribution of classes in the balanced dataset\nprint(balanced_df_train['claim'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:14:32.156732Z","iopub.execute_input":"2024-03-17T10:14:32.157418Z","iopub.status.idle":"2024-03-17T10:14:32.171309Z","shell.execute_reply.started":"2024-03-17T10:14:32.157384Z","shell.execute_reply":"2024-03-17T10:14:32.170278Z"},"trusted":true},"execution_count":124,"outputs":[{"name":"stdout","text":"claim\n0    880\n1    880\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train = balanced_df_train","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:14:32.820633Z","iopub.execute_input":"2024-03-17T10:14:32.820987Z","iopub.status.idle":"2024-03-17T10:14:32.825492Z","shell.execute_reply.started":"2024-03-17T10:14:32.820957Z","shell.execute_reply":"2024-03-17T10:14:32.824477Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing","metadata":{}},{"cell_type":"code","source":"import re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.model_selection import train_test_split\n\n# Download NLTK resources\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:14:35.384129Z","iopub.execute_input":"2024-03-17T10:14:35.384516Z","iopub.status.idle":"2024-03-17T10:14:35.393667Z","shell.execute_reply.started":"2024-03-17T10:14:35.384485Z","shell.execute_reply":"2024-03-17T10:14:35.392658Z"},"trusted":true},"execution_count":126,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":126,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"!python3 -m nltk.downloader wordnet\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:14:38.581549Z","iopub.execute_input":"2024-03-17T10:14:38.582332Z","iopub.status.idle":"2024-03-17T10:16:24.446988Z","shell.execute_reply.started":"2024-03-17T10:14:38.582293Z","shell.execute_reply":"2024-03-17T10:16:24.445756Z"},"trusted":true},"execution_count":127,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n  warn(RuntimeWarning(msg))\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nArchive:  /usr/share/nltk_data/corpora/wordnet.zip\nreplace /usr/share/nltk_data/corpora/wordnet/lexnames? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define preprocessing function\ndef preprocess_text(text):\n    # Remove punctuation\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    \n    # Convert text to lowercase\n    text = text.lower()\n    \n    # Tokenize text\n    tokens = word_tokenize(text)\n    \n    # Remove stopwords\n    stop_words = set(stopwords.words('english'))\n    tokens = [token for token in tokens if token not in stop_words]\n    \n    # Lemmatize tokens\n    lemmatizer = WordNetLemmatizer()\n    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n    \n    # Join tokens back into text\n    preprocessed_text = ' '.join(tokens)\n    \n    return preprocessed_text\n\n# Apply preprocessing to tweet_text column\ndf_train['preprocessed_text'] = df_train['tweet_text'].apply(preprocess_text)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:16:24.449033Z","iopub.execute_input":"2024-03-17T10:16:24.449380Z","iopub.status.idle":"2024-03-17T10:16:25.498967Z","shell.execute_reply.started":"2024-03-17T10:16:24.449342Z","shell.execute_reply":"2024-03-17T10:16:25.498158Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:16:25.500018Z","iopub.execute_input":"2024-03-17T10:16:25.500301Z","iopub.status.idle":"2024-03-17T10:16:25.511577Z","shell.execute_reply.started":"2024-03-17T10:16:25.500276Z","shell.execute_reply":"2024-03-17T10:16:25.510572Z"},"trusted":true},"execution_count":129,"outputs":[{"execution_count":129,"output_type":"execute_result","data":{"text/plain":"                                          tweet_text  claim  \\\n0  So here’s a question for today: if you are a d...      0   \n1  Wish he becomes the role model of getting cure...      0   \n2  Copper Kills Coronavirus. Why Aren’t Our Surfa...      0   \n3  Let’s hope #Covid_19 isn’t coming back once a ...      0   \n4  #NowThis\\n...people need to be reminded that #...      1   \n\n                                   preprocessed_text  \n0  ’ question today doctor seattle area today ord...  \n1  wish becomes role model getting cured self iso...  \n2  copper kill coronavirus ’ surface covered http...  \n3  let ’ hope covid19 ’ coming back cure vaccine ...  \n4  nowthis people need reminded coronavirus test ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_text</th>\n      <th>claim</th>\n      <th>preprocessed_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>So here’s a question for today: if you are a d...</td>\n      <td>0</td>\n      <td>’ question today doctor seattle area today ord...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Wish he becomes the role model of getting cure...</td>\n      <td>0</td>\n      <td>wish becomes role model getting cured self iso...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Copper Kills Coronavirus. Why Aren’t Our Surfa...</td>\n      <td>0</td>\n      <td>copper kill coronavirus ’ surface covered http...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Let’s hope #Covid_19 isn’t coming back once a ...</td>\n      <td>0</td>\n      <td>let ’ hope covid19 ’ coming back cure vaccine ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#NowThis\\n...people need to be reminded that #...</td>\n      <td>1</td>\n      <td>nowthis people need reminded coronavirus test ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Split data into features and labels\nX = df_train['preprocessed_text']\ny = df_train['claim']","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:16:25.513838Z","iopub.execute_input":"2024-03-17T10:16:25.514134Z","iopub.status.idle":"2024-03-17T10:16:25.521959Z","shell.execute_reply.started":"2024-03-17T10:16:25.514110Z","shell.execute_reply":"2024-03-17T10:16:25.521029Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"X_train = X\ny_train = y","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:16:25.523439Z","iopub.execute_input":"2024-03-17T10:16:25.523830Z","iopub.status.idle":"2024-03-17T10:16:25.531107Z","shell.execute_reply.started":"2024-03-17T10:16:25.523799Z","shell.execute_reply":"2024-03-17T10:16:25.530159Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"# loading the validation data for future use\ndf_val = pd.read_csv(\"/kaggle/input/ai-for-social-good-aries-iitd-x-kaizen-24/Public/Task 1/dev.csv\")\ndf_val.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T05:58:17.660040Z","iopub.execute_input":"2024-03-17T05:58:17.660700Z","iopub.status.idle":"2024-03-17T05:58:17.683731Z","shell.execute_reply.started":"2024-03-17T05:58:17.660667Z","shell.execute_reply":"2024-03-17T05:58:17.682743Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"                                          tweet_text  claim\n0  friends the stuff about nature healing and wil...      1\n1  A9. If you’re thinking of taking action based ...      1\n2  Kyle Turley, co-owner of Moreno Valley dispens...      1\n3                                          exhibit a      0\n4  The English edition of Marathi daily Lokmat pu...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_text</th>\n      <th>claim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>friends the stuff about nature healing and wil...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A9. If you’re thinking of taking action based ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Kyle Turley, co-owner of Moreno Valley dispens...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>exhibit a</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The English edition of Marathi daily Lokmat pu...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_val.describe()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T05:58:19.379802Z","iopub.execute_input":"2024-03-17T05:58:19.380201Z","iopub.status.idle":"2024-03-17T05:58:19.394926Z","shell.execute_reply.started":"2024-03-17T05:58:19.380160Z","shell.execute_reply":"2024-03-17T05:58:19.393802Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"             claim\ncount  1497.000000\nmean      0.869071\nstd       0.337435\nmin       0.000000\n25%       1.000000\n50%       1.000000\n75%       1.000000\nmax       1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>claim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1497.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.869071</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.337435</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#preprocess\ndf_val['preprocessed_text'] = df_val['tweet_text'].apply(preprocess_text)\n# Split data into features and labels\n\nX_val = df_val['preprocessed_text']\ny_val = df_val['claim']\n\n# Calculate lengths of each sentence in X_train\nsentence_lengths = [len(sentence.split()) for sentence in X_val]\n\n# Calculate mean and maximum length\nmean_length = sum(sentence_lengths) / len(sentence_lengths)\nmax_length = max(sentence_lengths)\n\nprint(\"Mean length of sentences:\", mean_length)\nprint(\"Maximum length of sentences:\", max_length)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T05:58:22.032907Z","iopub.execute_input":"2024-03-17T05:58:22.033975Z","iopub.status.idle":"2024-03-17T05:58:22.991554Z","shell.execute_reply.started":"2024-03-17T05:58:22.033937Z","shell.execute_reply":"2024-03-17T05:58:22.990579Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"Mean length of sentences: 16.733466933867735\nMaximum length of sentences: 50\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Word Embedding","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-03-17T10:16:37.636064Z","iopub.execute_input":"2024-03-17T10:16:37.636859Z","iopub.status.idle":"2024-03-17T10:16:50.419516Z","shell.execute_reply.started":"2024-03-17T10:16:37.636829Z","shell.execute_reply":"2024-03-17T10:16:50.418228Z"},"trusted":true},"execution_count":135,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nRequirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\n# Initialize Tokenizer\ntokenizer = Tokenizer()\n\n# Fit tokenizer on training data\ntokenizer.fit_on_texts(X_train)\n\n# Convert text to sequences\nX_train_sequences = tokenizer.texts_to_sequences(X_train)\n\n# Pad sequences to ensure uniform length\nmax_seq_length = 90  # adjust as needed\nX_train_padded = pad_sequences(X_train_sequences, maxlen=max_seq_length)\n\n# Print vocabulary size\nvocab_size = len(tokenizer.word_index) + 1\nprint(\"Vocabulary size:\", vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:16:55.083359Z","iopub.execute_input":"2024-03-17T10:16:55.084186Z","iopub.status.idle":"2024-03-17T10:16:55.200263Z","shell.execute_reply.started":"2024-03-17T10:16:55.084152Z","shell.execute_reply":"2024-03-17T10:16:55.199241Z"},"trusted":true},"execution_count":136,"outputs":[{"name":"stdout","text":"Vocabulary size: 7909\n","output_type":"stream"}]},{"cell_type":"code","source":"#exploring the data\n\n#get mean and max length of sentences in X_train\n# Calculate lengths of each sentence in X_train\nsentence_lengths = [len(sentence.split()) for sentence in X_train]\n\n# Calculate mean and maximum length\nmean_length = sum(sentence_lengths) / len(sentence_lengths)\nmax_length = max(sentence_lengths)\n\nprint(\"Mean length of sentences:\", mean_length)\nprint(\"Maximum length of sentences:\", max_length)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:16:58.299794Z","iopub.execute_input":"2024-03-17T10:16:58.300194Z","iopub.status.idle":"2024-03-17T10:16:58.309800Z","shell.execute_reply.started":"2024-03-17T10:16:58.300163Z","shell.execute_reply":"2024-03-17T10:16:58.308649Z"},"trusted":true},"execution_count":137,"outputs":[{"name":"stdout","text":"Mean length of sentences: 15.591477272727273\nMaximum length of sentences: 46\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Model : The RNN","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Embedding, SimpleRNN, Dense\n\n# Define RNN model\nmodel = Sequential()\nmodel.add(Embedding(input_dim=vocab_size, output_dim=100))\nmodel.add(SimpleRNN(units=64, activation='relu'))\nmodel.add(Dense(units=1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Print model summary\nprint(model.summary())\n\n# Train the model\nhistory = model.fit(X_train_padded, y_train, batch_size=32, epochs=10, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:18:25.332531Z","iopub.execute_input":"2024-03-16T19:18:25.332934Z","iopub.status.idle":"2024-03-16T19:21:29.445888Z","shell.execute_reply.started":"2024-03-16T19:18:25.332904Z","shell.execute_reply":"2024-03-16T19:21:29.445023Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, None, 100)         2251600   \n                                                                 \n simple_rnn (SimpleRNN)      (None, 64)                10560     \n                                                                 \n dense (Dense)               (None, 1)                 65        \n                                                                 \n=================================================================\nTotal params: 2262225 (8.63 MB)\nTrainable params: 2262225 (8.63 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\nNone\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1710616710.512447     124 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"175/175 [==============================] - 34s 177ms/step - loss: 0.4023 - accuracy: 0.8663 - val_loss: 0.3450 - val_accuracy: 0.8763\nEpoch 2/10\n175/175 [==============================] - 22s 123ms/step - loss: 0.2365 - accuracy: 0.8898 - val_loss: 0.3733 - val_accuracy: 0.8805\nEpoch 3/10\n175/175 [==============================] - 17s 96ms/step - loss: 0.1065 - accuracy: 0.9617 - val_loss: 0.4587 - val_accuracy: 0.8526\nEpoch 4/10\n175/175 [==============================] - 17s 99ms/step - loss: 0.0616 - accuracy: 0.9810 - val_loss: 0.5629 - val_accuracy: 0.8205\nEpoch 5/10\n175/175 [==============================] - 16s 91ms/step - loss: 0.0312 - accuracy: 0.9902 - val_loss: 0.5577 - val_accuracy: 0.8469\nEpoch 6/10\n175/175 [==============================] - 15s 87ms/step - loss: 0.0190 - accuracy: 0.9925 - val_loss: 0.7383 - val_accuracy: 0.8398\nEpoch 7/10\n175/175 [==============================] - 16s 90ms/step - loss: 0.0162 - accuracy: 0.9927 - val_loss: 0.6981 - val_accuracy: 0.8469\nEpoch 8/10\n175/175 [==============================] - 15s 87ms/step - loss: 0.0118 - accuracy: 0.9928 - val_loss: 0.8414 - val_accuracy: 0.8326\nEpoch 9/10\n175/175 [==============================] - 15s 84ms/step - loss: 0.0134 - accuracy: 0.9928 - val_loss: 0.7429 - val_accuracy: 0.8605\nEpoch 10/10\n175/175 [==============================] - 15s 83ms/step - loss: 0.0116 - accuracy: 0.9925 - val_loss: 0.8332 - val_accuracy: 0.7675\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:03:48.065706Z","iopub.execute_input":"2024-03-16T19:03:48.066097Z","iopub.status.idle":"2024-03-16T19:03:48.096054Z","shell.execute_reply.started":"2024-03-16T19:03:48.066068Z","shell.execute_reply":"2024-03-16T19:03:48.093757Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │     \u001b[38;5;34m2,251,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m10,560\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,251,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,560</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,786,677\u001b[0m (25.89 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,786,677</span> (25.89 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,262,225\u001b[0m (8.63 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,262,225</span> (8.63 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m4,524,452\u001b[0m (17.26 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,524,452</span> (17.26 MB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate the model on training data\ntrain_loss, train_accuracy = model.evaluate(X_train_padded, y_train)\nprint(\"Training Loss:\", train_loss)\nprint(\"Training Accuracy:\", train_accuracy)\n\n# Evaluate the model on validation data\nX_val_sequences = tokenizer.texts_to_sequences(X_val)  # Tokenize validation data\nX_val_padded = pad_sequences(X_val_sequences, maxlen=max_seq_length)  # Pad validation sequences\nval_loss, val_accuracy = model.evaluate(X_val_padded, y_val)\nprint(\"Validation Loss:\", val_loss)\nprint(\"Validation Accuracy:\", val_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:09:07.625278Z","iopub.execute_input":"2024-03-16T19:09:07.625761Z","iopub.status.idle":"2024-03-16T19:09:11.021942Z","shell.execute_reply.started":"2024-03-16T19:09:07.625726Z","shell.execute_reply":"2024-03-16T19:09:11.020535Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9914 - loss: 0.0265\nTraining Loss: 0.16137950122356415\nTraining Accuracy: 0.9655024409294128\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8282 - loss: 0.9019\nValidation Loss: 0.8503451943397522\nValidation Accuracy: 0.8336673378944397\n","output_type":"stream"}]},{"cell_type":"code","source":"rnn_model = model #saved the rnn model","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:22:37.000448Z","iopub.execute_input":"2024-03-16T19:22:37.000862Z","iopub.status.idle":"2024-03-16T19:22:37.005937Z","shell.execute_reply.started":"2024-03-16T19:22:37.000832Z","shell.execute_reply":"2024-03-16T19:22:37.004620Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"#### Model Part 1.5 : The RNN saved earlier","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\n\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, SimpleRNN, Dense\n\n# Define RNN model with mask_zero and saving history\nmodel_rnn_best = Sequential()\nmodel_rnn_best.add(Embedding(input_dim=vocab_size, output_dim=100, mask_zero=True))\nmodel_rnn_best.add(SimpleRNN(units=64, activation='relu'))\nmodel_rnn_best.add(Dense(units=1, activation='sigmoid'))\n\n# Compile the model\nmodel_rnn_best.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Define checkpoint callback\ncheckpoint = ModelCheckpoint(\"best_rnn_val.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\n# Train the model with checkpoint callback\nhistory_rnn_best = model_rnn_best.fit(X_train_padded, y_train, batch_size=32, epochs=10, validation_split=0.2, callbacks=[checkpoint])","metadata":{"execution":{"iopub.status.busy":"2024-03-17T05:58:49.742301Z","iopub.execute_input":"2024-03-17T05:58:49.743047Z","iopub.status.idle":"2024-03-17T05:59:39.631940Z","shell.execute_reply.started":"2024-03-17T05:58:49.743010Z","shell.execute_reply":"2024-03-17T05:59:39.630965Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Epoch 1/10\n44/44 [==============================] - ETA: 0s - loss: 0.6868 - accuracy: 0.5327\nEpoch 1: val_accuracy improved from -inf to 0.56818, saving model to best_rnn_val.h5\n44/44 [==============================] - 9s 173ms/step - loss: 0.6868 - accuracy: 0.5327 - val_loss: 0.6837 - val_accuracy: 0.5682\nEpoch 2/10\n44/44 [==============================] - ETA: 0s - loss: 0.5645 - accuracy: 0.8352\nEpoch 2: val_accuracy improved from 0.56818 to 0.58807, saving model to best_rnn_val.h5\n44/44 [==============================] - 6s 140ms/step - loss: 0.5645 - accuracy: 0.8352 - val_loss: 0.6569 - val_accuracy: 0.5881\nEpoch 3/10\n44/44 [==============================] - ETA: 0s - loss: 0.2063 - accuracy: 0.9538\nEpoch 3: val_accuracy improved from 0.58807 to 0.59375, saving model to best_rnn_val.h5\n44/44 [==============================] - 5s 114ms/step - loss: 0.2063 - accuracy: 0.9538 - val_loss: 0.7700 - val_accuracy: 0.5938\nEpoch 4/10\n44/44 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9901\nEpoch 4: val_accuracy did not improve from 0.59375\n44/44 [==============================] - 4s 99ms/step - loss: 0.0577 - accuracy: 0.9901 - val_loss: 0.9402 - val_accuracy: 0.5739\nEpoch 5/10\n44/44 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9929\nEpoch 5: val_accuracy did not improve from 0.59375\n44/44 [==============================] - 5s 109ms/step - loss: 0.0359 - accuracy: 0.9929 - val_loss: 1.0184 - val_accuracy: 0.5426\nEpoch 6/10\n44/44 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9950\nEpoch 6: val_accuracy did not improve from 0.59375\n44/44 [==============================] - 4s 97ms/step - loss: 0.0247 - accuracy: 0.9950 - val_loss: 0.8807 - val_accuracy: 0.5795\nEpoch 7/10\n44/44 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9950\nEpoch 7: val_accuracy did not improve from 0.59375\n44/44 [==============================] - 4s 84ms/step - loss: 0.0216 - accuracy: 0.9950 - val_loss: 0.9368 - val_accuracy: 0.5795\nEpoch 8/10\n44/44 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9964\nEpoch 8: val_accuracy did not improve from 0.59375\n44/44 [==============================] - 4s 88ms/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 1.2208 - val_accuracy: 0.5540\nEpoch 9/10\n44/44 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9972\nEpoch 9: val_accuracy improved from 0.59375 to 0.60227, saving model to best_rnn_val.h5\n44/44 [==============================] - 4s 92ms/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 0.9815 - val_accuracy: 0.6023\nEpoch 10/10\n44/44 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9972\nEpoch 10: val_accuracy did not improve from 0.60227\n44/44 [==============================] - 4s 94ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 1.1047 - val_accuracy: 0.5682\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.models import load_model","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:17:07.446210Z","iopub.execute_input":"2024-03-17T10:17:07.447054Z","iopub.status.idle":"2024-03-17T10:17:07.451375Z","shell.execute_reply.started":"2024-03-17T10:17:07.447022Z","shell.execute_reply":"2024-03-17T10:17:07.450279Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on training data\n# Load the saved model\nloaded_model = load_model(\"best_rnn_val.h5\")\ntrain_loss, train_accuracy = loaded_model.evaluate(X_train_padded, y_train)\nprint(\"Training Loss:\", train_loss)\nprint(\"Training Accuracy:\", train_accuracy)\n\n# Evaluate the model on validation data\nX_val_sequences = tokenizer.texts_to_sequences(X_val)  # Tokenize validation data\nmax_val_length = max(len(sequence) for sequence in X_val_sequences)\nX_val_padded = pad_sequences(X_val_sequences, maxlen=max_val_length)  # Pad validation sequences\nval_loss, val_accuracy = loaded_model.evaluate(X_val_padded, y_val)\nprint(\"Validation Loss:\", val_loss)\nprint(\"Validation Accuracy:\", val_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T05:59:55.278233Z","iopub.execute_input":"2024-03-17T05:59:55.278642Z","iopub.status.idle":"2024-03-17T05:59:57.023019Z","shell.execute_reply.started":"2024-03-17T05:59:55.278609Z","shell.execute_reply":"2024-03-17T05:59:57.021980Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"55/55 [==============================] - 1s 12ms/step - loss: 0.2040 - accuracy: 0.9187\nTraining Loss: 0.20403744280338287\nTraining Accuracy: 0.918749988079071\n47/47 [==============================] - 1s 7ms/step - loss: 0.9838 - accuracy: 0.5979\nValidation Loss: 0.9838300347328186\nValidation Accuracy: 0.5978623628616333\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Model Part II: The LSTM (with dropout)","metadata":{}},{"cell_type":"code","source":"#lets create LSTM model with dropouts\nfrom keras.layers import LSTM, Dropout\n\n# Define enhanced model with LSTM and Dropout\nlstm_model = Sequential()\nlstm_model.add(Embedding(input_dim=vocab_size, output_dim=100))\nlstm_model.add(LSTM(units=64, activation='tanh', return_sequences=True))  # LSTM layer with return_sequences=True for stacking\nlstm_model.add(Dropout(0.2))  # Dropout layer to reduce overfitting\nlstm_model.add(LSTM(units=32, activation='tanh'))  # Second LSTM layer\nlstm_model.add(Dense(units=1, activation='sigmoid'))\n\n# Compile the model\nlstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nhistory_lstm = lstm_model.fit(X_train_padded, y_train, batch_size=32, epochs=10, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:22:41.041452Z","iopub.execute_input":"2024-03-16T19:22:41.041894Z","iopub.status.idle":"2024-03-16T19:24:06.785940Z","shell.execute_reply.started":"2024-03-16T19:22:41.041862Z","shell.execute_reply":"2024-03-16T19:24:06.784966Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/10\n175/175 [==============================] - 19s 78ms/step - loss: 0.3866 - accuracy: 0.8724 - val_loss: 0.3545 - val_accuracy: 0.8763\nEpoch 2/10\n175/175 [==============================] - 6s 34ms/step - loss: 0.2780 - accuracy: 0.8885 - val_loss: 0.3548 - val_accuracy: 0.8684\nEpoch 3/10\n175/175 [==============================] - 4s 22ms/step - loss: 0.1412 - accuracy: 0.9488 - val_loss: 0.4382 - val_accuracy: 0.8698\nEpoch 4/10\n175/175 [==============================] - 3s 16ms/step - loss: 0.0791 - accuracy: 0.9723 - val_loss: 0.5524 - val_accuracy: 0.8433\nEpoch 5/10\n175/175 [==============================] - 3s 16ms/step - loss: 0.0527 - accuracy: 0.9837 - val_loss: 0.5233 - val_accuracy: 0.8097\nEpoch 6/10\n175/175 [==============================] - 3s 17ms/step - loss: 0.0378 - accuracy: 0.9884 - val_loss: 0.6572 - val_accuracy: 0.8355\nEpoch 7/10\n175/175 [==============================] - 3s 15ms/step - loss: 0.0267 - accuracy: 0.9905 - val_loss: 0.6795 - val_accuracy: 0.8562\nEpoch 8/10\n175/175 [==============================] - 3s 16ms/step - loss: 0.0193 - accuracy: 0.9911 - val_loss: 0.8195 - val_accuracy: 0.8441\nEpoch 9/10\n175/175 [==============================] - 2s 13ms/step - loss: 0.0155 - accuracy: 0.9930 - val_loss: 0.8066 - val_accuracy: 0.8312\nEpoch 10/10\n175/175 [==============================] - 3s 16ms/step - loss: 0.0131 - accuracy: 0.9925 - val_loss: 0.7950 - val_accuracy: 0.8412\n","output_type":"stream"}]},{"cell_type":"code","source":"#testing the LSTM\n# Evaluate the model on training data\ntrain_loss, train_accuracy = lstm_model.evaluate(X_train_padded, y_train)\nprint(\"Training Loss:\", train_loss)\nprint(\"Training Accuracy:\", train_accuracy)\n\n# Evaluate the model on validation data\nX_val_sequences = tokenizer.texts_to_sequences(X_val)  # Tokenize validation data\nX_val_padded = pad_sequences(X_val_sequences, maxlen=max_seq_length)  # Pad validation sequences\nval_loss, val_accuracy = lstm_model.evaluate(X_val_padded, y_val)\nprint(\"Validation Loss:\", val_loss)\nprint(\"Validation Accuracy:\", val_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:24:06.788101Z","iopub.execute_input":"2024-03-16T19:24:06.788853Z","iopub.status.idle":"2024-03-16T19:24:08.501432Z","shell.execute_reply.started":"2024-03-16T19:24:06.788812Z","shell.execute_reply":"2024-03-16T19:24:08.500569Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"219/219 [==============================] - 1s 6ms/step - loss: 0.1670 - accuracy: 0.9642\nTraining Loss: 0.16704432666301727\nTraining Accuracy: 0.9642141461372375\n47/47 [==============================] - 0s 5ms/step - loss: 0.9125 - accuracy: 0.8410\nValidation Loss: 0.9125417470932007\nValidation Accuracy: 0.8410153388977051\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Model Part 2.5: The LSTM with no padding","metadata":{}},{"cell_type":"code","source":"#lets create LSTM model with dropouts\nfrom keras.layers import LSTM, Dropout","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:17:13.569949Z","iopub.execute_input":"2024-03-17T10:17:13.570300Z","iopub.status.idle":"2024-03-17T10:17:13.574735Z","shell.execute_reply.started":"2024-03-17T10:17:13.570276Z","shell.execute_reply":"2024-03-17T10:17:13.573706Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"# Define enhanced model with LSTM and Dropout\nlstm_model_pad = Sequential()\nlstm_model_pad.add(Embedding(input_dim=vocab_size, output_dim=100, mask_zero = True))\nlstm_model_pad.add(LSTM(units=64, activation='tanh', return_sequences=True))  # LSTM layer with return_sequences=True for stacking\nlstm_model_pad.add(Dropout(0.2))  # Dropout layer to reduce overfitting\nlstm_model_pad.add(LSTM(units=32, activation='tanh'))  # Second LSTM layer\nlstm_model_pad.add(Dense(units=1, activation='sigmoid'))\n\n# Compile the model\nlstm_model_pad.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nhistory_lstm_pad = lstm_model_pad.fit(X_train_padded, y_train, batch_size=32, epochs=10, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:28:02.877773Z","iopub.execute_input":"2024-03-16T19:28:02.878784Z","iopub.status.idle":"2024-03-16T19:39:33.486889Z","shell.execute_reply.started":"2024-03-16T19:28:02.878748Z","shell.execute_reply":"2024-03-16T19:39:33.485631Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Epoch 1/10\n175/175 [==============================] - 89s 458ms/step - loss: 0.3755 - accuracy: 0.8713 - val_loss: 0.3266 - val_accuracy: 0.8777\nEpoch 2/10\n175/175 [==============================] - 68s 390ms/step - loss: 0.2251 - accuracy: 0.9086 - val_loss: 0.3681 - val_accuracy: 0.8763\nEpoch 3/10\n175/175 [==============================] - 67s 385ms/step - loss: 0.1163 - accuracy: 0.9596 - val_loss: 0.4524 - val_accuracy: 0.8591\nEpoch 4/10\n175/175 [==============================] - 66s 377ms/step - loss: 0.0772 - accuracy: 0.9757 - val_loss: 0.5020 - val_accuracy: 0.8176\nEpoch 5/10\n175/175 [==============================] - 66s 374ms/step - loss: 0.0574 - accuracy: 0.9823 - val_loss: 0.5746 - val_accuracy: 0.8205\nEpoch 6/10\n175/175 [==============================] - 66s 379ms/step - loss: 0.0435 - accuracy: 0.9875 - val_loss: 0.5891 - val_accuracy: 0.8391\nEpoch 7/10\n175/175 [==============================] - 66s 378ms/step - loss: 0.0355 - accuracy: 0.9889 - val_loss: 0.7237 - val_accuracy: 0.8054\nEpoch 8/10\n175/175 [==============================] - 66s 377ms/step - loss: 0.0272 - accuracy: 0.9896 - val_loss: 0.6586 - val_accuracy: 0.8255\nEpoch 9/10\n175/175 [==============================] - 65s 373ms/step - loss: 0.0204 - accuracy: 0.9902 - val_loss: 0.9002 - val_accuracy: 0.8398\nEpoch 10/10\n175/175 [==============================] - 66s 375ms/step - loss: 0.0170 - accuracy: 0.9914 - val_loss: 0.9831 - val_accuracy: 0.8169\n","output_type":"stream"}]},{"cell_type":"code","source":"#testing the LSTM (ignore pad model)\n# Evaluate the model on training data\ntrain_loss, train_accuracy = lstm_model_pad.evaluate(X_train_padded, y_train)\nprint(\"Training Loss:\", train_loss)\nprint(\"Training Accuracy:\", train_accuracy)\n\n# Evaluate the model on validation data\nX_val_sequences = tokenizer.texts_to_sequences(X_val)  # Tokenize validation data\nX_val_padded = pad_sequences(X_val_sequences, maxlen=max_seq_length)  # Pad validation sequences\nval_loss, val_accuracy = lstm_model_pad.evaluate(X_val_padded, y_val)\nprint(\"Validation Loss:\", val_loss)\nprint(\"Validation Accuracy:\", val_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:39:33.489313Z","iopub.execute_input":"2024-03-16T19:39:33.489631Z","iopub.status.idle":"2024-03-16T19:39:43.856456Z","shell.execute_reply.started":"2024-03-16T19:39:33.489603Z","shell.execute_reply":"2024-03-16T19:39:43.855518Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"219/219 [==============================] - 8s 38ms/step - loss: 0.2064 - accuracy: 0.9586\nTraining Loss: 0.20639245212078094\nTraining Accuracy: 0.9586315751075745\n47/47 [==============================] - 2s 38ms/step - loss: 1.0837 - accuracy: 0.8103\nValidation Loss: 1.083691120147705\nValidation Accuracy: 0.8102872371673584\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Model : LSTM with best saved","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\n\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, SimpleRNN, Dense\n\n# Define enhanced model with LSTM and Dropout\nlstm_model_pad_best = Sequential()\nlstm_model_pad_best.add(Embedding(input_dim=vocab_size, output_dim=100, mask_zero = True))\nlstm_model_pad_best.add(LSTM(units=64, activation='tanh', return_sequences=True))  # LSTM layer with return_sequences=True for stacking\nlstm_model_pad_best.add(Dropout(0.2))  # Dropout layer to reduce overfitting\nlstm_model_pad_best.add(LSTM(units=32, activation='tanh'))  # Second LSTM layer\nlstm_model_pad_best.add(Dense(units=1, activation='sigmoid'))\n\n# Compile the model\nlstm_model_pad_best.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Define checkpoint callback\ncheckpoint = ModelCheckpoint(\"best_lstm_val.keras\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\n# Train the model with checkpoint callback\nhistory_lstm_best = lstm_model_pad_best.fit(X_train_padded, y_train, batch_size=32, epochs=10, validation_split=0.2, callbacks=[checkpoint])","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-03-17T10:19:25.247364Z","iopub.execute_input":"2024-03-17T10:19:25.247733Z","iopub.status.idle":"2024-03-17T10:20:54.461682Z","shell.execute_reply.started":"2024-03-17T10:19:25.247702Z","shell.execute_reply":"2024-03-17T10:20:54.460811Z"},"trusted":true},"execution_count":143,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.4867 - loss: 0.6886\nEpoch 1: val_accuracy improved from -inf to 0.67330, saving model to best_lstm_val.keras\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 197ms/step - accuracy: 0.4879 - loss: 0.6883 - val_accuracy: 0.6733 - val_loss: 0.6252\nEpoch 2/10\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8451 - loss: 0.4308\nEpoch 2: val_accuracy did not improve from 0.67330\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 189ms/step - accuracy: 0.8449 - loss: 0.4301 - val_accuracy: 0.6506 - val_loss: 0.7030\nEpoch 3/10\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9467 - loss: 0.1684\nEpoch 3: val_accuracy did not improve from 0.67330\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 192ms/step - accuracy: 0.9467 - loss: 0.1683 - val_accuracy: 0.6364 - val_loss: 0.9032\nEpoch 4/10\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9788 - loss: 0.0740\nEpoch 4: val_accuracy did not improve from 0.67330\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 191ms/step - accuracy: 0.9788 - loss: 0.0741 - val_accuracy: 0.6392 - val_loss: 1.1667\nEpoch 5/10\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.9866 - loss: 0.0433\nEpoch 5: val_accuracy did not improve from 0.67330\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 187ms/step - accuracy: 0.9866 - loss: 0.0435 - val_accuracy: 0.6250 - val_loss: 1.1978\nEpoch 6/10\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9916 - loss: 0.0476\nEpoch 6: val_accuracy did not improve from 0.67330\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 191ms/step - accuracy: 0.9917 - loss: 0.0476 - val_accuracy: 0.6364 - val_loss: 1.4526\nEpoch 7/10\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9961 - loss: 0.0275\nEpoch 7: val_accuracy did not improve from 0.67330\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 195ms/step - accuracy: 0.9961 - loss: 0.0275 - val_accuracy: 0.6335 - val_loss: 1.4075\nEpoch 8/10\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9982 - loss: 0.0163\nEpoch 8: val_accuracy did not improve from 0.67330\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 191ms/step - accuracy: 0.9981 - loss: 0.0164 - val_accuracy: 0.6364 - val_loss: 1.6391\nEpoch 9/10\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9945 - loss: 0.0221\nEpoch 9: val_accuracy did not improve from 0.67330\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 194ms/step - accuracy: 0.9945 - loss: 0.0222 - val_accuracy: 0.6420 - val_loss: 1.5774\nEpoch 10/10\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9937 - loss: 0.0215\nEpoch 10: val_accuracy did not improve from 0.67330\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 189ms/step - accuracy: 0.9937 - loss: 0.0215 - val_accuracy: 0.6364 - val_loss: 1.6077\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model on training data\n# Load the saved model\nbest_lstm_model = load_model(\"best_lstm_val.keras\")\ntrain_loss, train_accuracy = best_lstm_model.evaluate(X_train_padded, y_train)\nprint(\"Training Loss:\", train_loss)\nprint(\"Training Accuracy:\", train_accuracy)\n\n# Evaluate the model on validation data\n\nX_val_sequences = tokenizer.texts_to_sequences(X_val)  # Tokenize validation data\nmax_val_length = max(len(sequence) for sequence in X_val_sequences)\nX_val_padded = pad_sequences(X_val_sequences, maxlen=max_val_length)  # Pad validation sequences\nval_loss, val_accuracy = best_lstm_model.evaluate(X_val_padded, y_val)\nprint(\"Validation Loss:\", val_loss)\nprint(\"Validation Accuracy:\", val_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:18:45.525696Z","iopub.execute_input":"2024-03-17T10:18:45.526010Z","iopub.status.idle":"2024-03-17T10:18:49.834661Z","shell.execute_reply.started":"2024-03-17T10:18:45.525982Z","shell.execute_reply":"2024-03-17T10:18:49.833213Z"},"trusted":true},"execution_count":141,"outputs":[{"name":"stdout","text":"\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.9842 - loss: 0.0709\nTraining Loss: 0.27611351013183594\nTraining Accuracy: 0.9227272868156433\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[141], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_accuracy)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Evaluate the model on validation data\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m X_val_sequences \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences(\u001b[43mX_val\u001b[49m)  \u001b[38;5;66;03m# Tokenize validation data\u001b[39;00m\n\u001b[1;32m     11\u001b[0m max_val_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sequence) \u001b[38;5;28;01mfor\u001b[39;00m sequence \u001b[38;5;129;01min\u001b[39;00m X_val_sequences)\n\u001b[1;32m     12\u001b[0m X_val_padded \u001b[38;5;241m=\u001b[39m pad_sequences(X_val_sequences, maxlen\u001b[38;5;241m=\u001b[39mmax_val_length)  \u001b[38;5;66;03m# Pad validation sequences\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'X_val' is not defined"],"ename":"NameError","evalue":"name 'X_val' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"### LSTM with dropout, regularisation, normaliastion","metadata":{}},{"cell_type":"code","source":"from keras.layers import Dropout, BatchNormalization, LSTM\nfrom keras.regularizers import l2\n\n# Define enhanced model with LSTM, Dropout, Regularization, and Batch Normalization\nlstm_model_pad_norm_best = Sequential()\nlstm_model_pad_norm_best.add(Embedding(input_dim=vocab_size, output_dim=100, mask_zero=True))\nlstm_model_pad_norm_best.add(LSTM(units=64, activation='tanh', return_sequences=True, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))  # LSTM layer with return_sequences=True for stacking\nlstm_model_pad_norm_best.add(Dropout(0.2))  # Dropout layer to reduce overfitting\nlstm_model_pad_norm_best.add(BatchNormalization())  # Batch normalization layer\nlstm_model_pad_norm_best.add(LSTM(units=32, activation='tanh', kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))  # Second LSTM layer\nlstm_model_pad_norm_best.add(Dropout(0.2))  # Dropout layer to reduce overfitting\nlstm_model_pad_norm_best.add(BatchNormalization())  # Batch normalization layer\nlstm_model_pad_norm_best.add(Dense(units=1, activation='sigmoid'))\n\n# Compile the model\nlstm_model_pad_norm_best.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Define checkpoint callback\ncheckpoint = ModelCheckpoint(\"best_lstm_norm_val.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\n# Train the model with checkpoint callback\nhistory_lstm_norm_best = lstm_model_pad_norm_best.fit(X_train_padded, y_train, batch_size=32, epochs=15, validation_split=0.2, callbacks=[checkpoint])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:31:12.781642Z","iopub.execute_input":"2024-03-17T06:31:12.782441Z","iopub.status.idle":"2024-03-17T06:34:08.681832Z","shell.execute_reply.started":"2024-03-17T06:31:12.782406Z","shell.execute_reply":"2024-03-17T06:34:08.680831Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"Epoch 1/15\n44/44 [==============================] - ETA: 0s - loss: 4.0383 - accuracy: 0.6080\nEpoch 1: val_accuracy improved from -inf to 0.65341, saving model to best_lstm_norm_val.h5\n44/44 [==============================] - 22s 327ms/step - loss: 4.0383 - accuracy: 0.6080 - val_loss: 3.2900 - val_accuracy: 0.6534\nEpoch 2/15\n44/44 [==============================] - ETA: 0s - loss: 2.4881 - accuracy: 0.8750\nEpoch 2: val_accuracy improved from 0.65341 to 0.65909, saving model to best_lstm_norm_val.h5\n44/44 [==============================] - 10s 237ms/step - loss: 2.4881 - accuracy: 0.8750 - val_loss: 2.5134 - val_accuracy: 0.6591\nEpoch 3/15\n44/44 [==============================] - ETA: 0s - loss: 1.7434 - accuracy: 0.9553\nEpoch 3: val_accuracy did not improve from 0.65909\n44/44 [==============================] - 10s 224ms/step - loss: 1.7434 - accuracy: 0.9553 - val_loss: 2.1001 - val_accuracy: 0.6591\nEpoch 4/15\n44/44 [==============================] - ETA: 0s - loss: 1.3564 - accuracy: 0.9858\nEpoch 4: val_accuracy did not improve from 0.65909\n44/44 [==============================] - 9s 193ms/step - loss: 1.3564 - accuracy: 0.9858 - val_loss: 1.8362 - val_accuracy: 0.6591\nEpoch 5/15\n44/44 [==============================] - ETA: 0s - loss: 1.1412 - accuracy: 0.9822\nEpoch 5: val_accuracy improved from 0.65909 to 0.66193, saving model to best_lstm_norm_val.h5\n44/44 [==============================] - 9s 209ms/step - loss: 1.1412 - accuracy: 0.9822 - val_loss: 1.6451 - val_accuracy: 0.6619\nEpoch 6/15\n44/44 [==============================] - ETA: 0s - loss: 0.9702 - accuracy: 0.9886\nEpoch 6: val_accuracy improved from 0.66193 to 0.66761, saving model to best_lstm_norm_val.h5\n44/44 [==============================] - 9s 196ms/step - loss: 0.9702 - accuracy: 0.9886 - val_loss: 1.4937 - val_accuracy: 0.6676\nEpoch 7/15\n44/44 [==============================] - ETA: 0s - loss: 0.8191 - accuracy: 0.9915\nEpoch 7: val_accuracy did not improve from 0.66761\n44/44 [==============================] - 9s 195ms/step - loss: 0.8191 - accuracy: 0.9915 - val_loss: 1.3681 - val_accuracy: 0.6562\nEpoch 8/15\n44/44 [==============================] - ETA: 0s - loss: 0.7156 - accuracy: 0.9936\nEpoch 8: val_accuracy did not improve from 0.66761\n44/44 [==============================] - 8s 188ms/step - loss: 0.7156 - accuracy: 0.9936 - val_loss: 1.2662 - val_accuracy: 0.6506\nEpoch 9/15\n44/44 [==============================] - ETA: 0s - loss: 0.6258 - accuracy: 0.9936\nEpoch 9: val_accuracy did not improve from 0.66761\n44/44 [==============================] - 8s 193ms/step - loss: 0.6258 - accuracy: 0.9936 - val_loss: 1.1859 - val_accuracy: 0.6392\nEpoch 10/15\n44/44 [==============================] - ETA: 0s - loss: 0.5409 - accuracy: 0.9908\nEpoch 10: val_accuracy did not improve from 0.66761\n44/44 [==============================] - 9s 202ms/step - loss: 0.5409 - accuracy: 0.9908 - val_loss: 1.1163 - val_accuracy: 0.6477\nEpoch 11/15\n44/44 [==============================] - ETA: 0s - loss: 0.4805 - accuracy: 0.9893\nEpoch 11: val_accuracy did not improve from 0.66761\n44/44 [==============================] - 9s 195ms/step - loss: 0.4805 - accuracy: 0.9893 - val_loss: 1.0569 - val_accuracy: 0.6420\nEpoch 12/15\n44/44 [==============================] - ETA: 0s - loss: 0.4155 - accuracy: 0.9915\nEpoch 12: val_accuracy did not improve from 0.66761\n44/44 [==============================] - 8s 178ms/step - loss: 0.4155 - accuracy: 0.9915 - val_loss: 1.0233 - val_accuracy: 0.6477\nEpoch 13/15\n44/44 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.9901\nEpoch 13: val_accuracy did not improve from 0.66761\n44/44 [==============================] - 8s 180ms/step - loss: 0.3851 - accuracy: 0.9901 - val_loss: 1.0264 - val_accuracy: 0.6193\nEpoch 14/15\n44/44 [==============================] - ETA: 0s - loss: 0.3244 - accuracy: 0.9929\nEpoch 14: val_accuracy did not improve from 0.66761\n44/44 [==============================] - 8s 190ms/step - loss: 0.3244 - accuracy: 0.9929 - val_loss: 1.0784 - val_accuracy: 0.6449\nEpoch 15/15\n44/44 [==============================] - ETA: 0s - loss: 0.2809 - accuracy: 0.9957\nEpoch 15: val_accuracy did not improve from 0.66761\n44/44 [==============================] - 8s 180ms/step - loss: 0.2809 - accuracy: 0.9957 - val_loss: 1.0429 - val_accuracy: 0.6420\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model on training data\n# Load the saved model\nbest_lstm_norm_model = load_model(\"best_lstm_norm_val.h5\")\ntrain_loss, train_accuracy = best_lstm_norm_model.evaluate(X_train_padded, y_train)\nprint(\"Training Loss:\", train_loss)\nprint(\"Training Accuracy:\", train_accuracy)\n\n# Evaluate the model on validation data\n\nX_val_sequences = tokenizer.texts_to_sequences(X_val)  # Tokenize validation data\nmax_val_length = max(len(sequence) for sequence in X_val_sequences)\nX_val_padded = pad_sequences(X_val_sequences, maxlen=max_val_length)  # Pad validation sequences\nval_loss, val_accuracy = best_lstm_norm_model.evaluate(X_val_padded, y_val)\nprint(\"Validation Loss:\", val_loss)\nprint(\"Validation Accuracy:\", val_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:19:00.542783Z","iopub.execute_input":"2024-03-17T10:19:00.543193Z","iopub.status.idle":"2024-03-17T10:19:00.771944Z","shell.execute_reply.started":"2024-03-17T10:19:00.543160Z","shell.execute_reply":"2024-03-17T10:19:00.770490Z"},"scrolled":true,"trusted":true},"execution_count":142,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[142], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model on training data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Load the saved model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m best_lstm_norm_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_lstm_norm_val.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m best_lstm_norm_model\u001b[38;5;241m.\u001b[39mevaluate(X_train_padded, y_train)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_loss)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.saving.load_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.models.load_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\n\u001b[1;32m    178\u001b[0m     filepath, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, safe_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    179\u001b[0m ):\n\u001b[1;32m    180\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a model saved via `model.save()`.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;124;03m        filepath: `str` or `pathlib.Path` object, path to the saved model file.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m        custom_objects: Optional dictionary mapping names\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m            (strings) to custom classes or functions to be\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m            considered during deserialization.\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m        compile: Boolean, whether to compile the model after loading.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m        safe_mode: Boolean, whether to disallow unsafe `lambda` deserialization.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m            When `safe_mode=False`, loading an object has the potential to\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m            trigger arbitrary code execution. This argument is only\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m            applicable to the Keras v3 model format. Defaults to True.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m    SavedModel format arguments:\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m        options: Only applies to SavedModel format.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m            Optional `tf.saved_model.LoadOptions` object that specifies\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m            SavedModel loading options.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m        A Keras model instance. If the original model was compiled,\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m        and the argument `compile=True` is set, then the returned model\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m        will be compiled. Otherwise, the model will be left uncompiled.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    ```python\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    model = tf.keras.Sequential([\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        tf.keras.layers.Dense(5, input_shape=(3,)),\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m        tf.keras.layers.Softmax()])\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m    model.save(\"model.keras\")\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    loaded_model = tf.keras.saving.load_model(\"model.keras\")\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m    x = tf.random.uniform((10, 3))\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m    assert np.allclose(model.predict(x), loaded_model.predict(x))\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    Note that the model variables may have different name values\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m    (`var.name` property, e.g. `\"dense_1/kernel:0\"`) after being reloaded.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m    It is recommended that you use layer attributes to\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# Supports GCS URIs by copying data to temporary file\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     save_format \u001b[38;5;241m=\u001b[39m get_save_format(filepath, save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/legacy/saving/legacy_h5_format.py:116\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n","File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'best_lstm_norm_val.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"],"ename":"FileNotFoundError","evalue":"[Errno 2] Unable to synchronously open file (unable to open file: name = 'best_lstm_norm_val.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)","output_type":"error"}]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/ai-for-social-good-aries-iitd-x-kaizen-24/Public/submission_format.csv')\ndf_test = pd.read_csv('/kaggle/input/ai-hackthon-aravind/ans.csv')\ndf_test = pd.read_csv('/kaggle/input/ai-hackathon-ara-2/ans (1).csv')\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:40:47.335945Z","iopub.execute_input":"2024-03-17T10:40:47.336854Z","iopub.status.idle":"2024-03-17T10:40:47.407443Z","shell.execute_reply.started":"2024-03-17T10:40:47.336809Z","shell.execute_reply":"2024-03-17T10:40:47.406392Z"},"trusted":true},"execution_count":196,"outputs":[{"execution_count":196,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0  ID                                               text  claim  \\\n0           0   0  Of course we should have captured Osama Bin La...      1   \n1           1   1  covid19 will end soon amen covid19 will end so...      0   \n2           2   2  #Coronavirus #SanDiego #1 #Hotspot #92103 # Co...      1   \n3           3   3  @ICannot_Enough @elonmusk Yes it is. Because $...      0   \n4           4   4  Some people are saying black people are immune...      1   \n\n  span_start_index span_end_index  task  \n0             [-2]           [-2]     1  \n1             [-2]           [-2]     1  \n2             [-2]           [-2]     1  \n3             [-2]           [-2]     1  \n4             [-2]           [-2]     1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>ID</th>\n      <th>text</th>\n      <th>claim</th>\n      <th>span_start_index</th>\n      <th>span_end_index</th>\n      <th>task</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>Of course we should have captured Osama Bin La...</td>\n      <td>1</td>\n      <td>[-2]</td>\n      <td>[-2]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>covid19 will end soon amen covid19 will end so...</td>\n      <td>0</td>\n      <td>[-2]</td>\n      <td>[-2]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>#Coronavirus #SanDiego #1 #Hotspot #92103 # Co...</td>\n      <td>1</td>\n      <td>[-2]</td>\n      <td>[-2]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>@ICannot_Enough @elonmusk Yes it is. Because $...</td>\n      <td>0</td>\n      <td>[-2]</td>\n      <td>[-2]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>Some people are saying black people are immune...</td>\n      <td>1</td>\n      <td>[-2]</td>\n      <td>[-2]</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#note: 17th march 0111hrs, using GPU x2 T4","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:21:38.758017Z","iopub.execute_input":"2024-03-17T10:21:38.758716Z","iopub.status.idle":"2024-03-17T10:21:38.762661Z","shell.execute_reply.started":"2024-03-17T10:21:38.758678Z","shell.execute_reply":"2024-03-17T10:21:38.761614Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"#preprocess\ndf_test['preprocessed_text'] = df_test['text'].apply(preprocess_text)\nX_test = df_test['preprocessed_text']\n# Split data into features and labels\n# Calculate lengths of each sentence in X_train\nsentence_lengths = [len(sentence.split()) for sentence in X_test]\n\n# Calculate mean and maximum length\nmean_length = sum(sentence_lengths) / len(sentence_lengths)\nmax_length = max(sentence_lengths)\n\nprint(\"Mean length of sentences:\", mean_length)\nprint(\"Maximum length of sentences:\", max_length)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:21:39.354259Z","iopub.execute_input":"2024-03-17T10:21:39.355094Z","iopub.status.idle":"2024-03-17T10:21:40.768734Z","shell.execute_reply.started":"2024-03-17T10:21:39.355060Z","shell.execute_reply":"2024-03-17T10:21:40.767761Z"},"trusted":true},"execution_count":147,"outputs":[{"name":"stdout","text":"Mean length of sentences: 16.655570350643586\nMaximum length of sentences: 74\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tqdm\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:21:43.183948Z","iopub.execute_input":"2024-03-17T10:21:43.184805Z","iopub.status.idle":"2024-03-17T10:21:55.516681Z","shell.execute_reply.started":"2024-03-17T10:21:43.184775Z","shell.execute_reply":"2024-03-17T10:21:55.515481Z"},"trusted":true},"execution_count":148,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"cur_model = best_lstm_model\ncur_max_seq_length = max_length\n\nX_test_sequences = tokenizer.texts_to_sequences(X_test)  # Tokenize validation data\nmax_test_length = max(len(sequence) for sequence in X_test_sequences)\nX_test_padded = pad_sequences(X_test_sequences, maxlen=max_test_length)\npredictions = cur_model.predict(X_test_padded, verbose=False)\npredictions = (predictions > 0.5).astype(int)\n\nfor index, row in tqdm(df_test.iterrows(), total=len(df_test), leave=True):\n    if row['task'] == 1:  # Check if task is 1\n        # Update the 'claim' column with the model prediction\n        df_test.at[index, 'claim'] = predictions[index]\n\n# Save the modified DataFrame to a new CSV file\ndf_test.drop(columns=['preprocessed_text'], inplace=True)\ndf_test.to_csv('submission.csv', index=False)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-03-17T10:21:55.518895Z","iopub.execute_input":"2024-03-17T10:21:55.519216Z","iopub.status.idle":"2024-03-17T10:21:58.173684Z","shell.execute_reply.started":"2024-03-17T10:21:55.519188Z","shell.execute_reply":"2024-03-17T10:21:58.172803Z"},"trusted":true},"execution_count":149,"outputs":[{"name":"stderr","text":"100%|██████████| 2253/2253 [00:00<00:00, 12067.64it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"df_test.iloc[[224]]","metadata":{"execution":{"iopub.status.busy":"2024-03-16T19:55:18.412779Z","iopub.execute_input":"2024-03-16T19:55:18.413516Z","iopub.status.idle":"2024-03-16T19:55:18.438019Z","shell.execute_reply.started":"2024-03-16T19:55:18.413481Z","shell.execute_reply":"2024-03-16T19:55:18.436765Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"                                            tweet_text  \\\n224  Congratulations 🥳🥳🥳Since our police force have...   \n\n                                     preprocessed_text  \n224  congratulation 🥳🥳🥳since police force finally f...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_text</th>\n      <th>preprocessed_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>224</th>\n      <td>Congratulations 🥳🥳🥳Since our police force have...</td>\n      <td>congratulation 🥳🥳🥳since police force finally f...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Task 2 : Claim Span Prediction","metadata":{}},{"cell_type":"code","source":"df_train2 = pd.read_csv(\"/kaggle/input/ai-for-social-good-aries-iitd-x-kaizen-24/Public/Task 2/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:22:10.871140Z","iopub.execute_input":"2024-03-17T10:22:10.872095Z","iopub.status.idle":"2024-03-17T10:22:10.915906Z","shell.execute_reply.started":"2024-03-17T10:22:10.872061Z","shell.execute_reply":"2024-03-17T10:22:10.914061Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"df_train2.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:22:11.826823Z","iopub.execute_input":"2024-03-17T10:22:11.827459Z","iopub.status.idle":"2024-03-17T10:22:11.838038Z","shell.execute_reply.started":"2024-03-17T10:22:11.827428Z","shell.execute_reply":"2024-03-17T10:22:11.837034Z"},"trusted":true},"execution_count":151,"outputs":[{"execution_count":151,"output_type":"execute_result","data":{"text/plain":"                                              tokens span_start_index  \\\n0  ['\"who', ' may', ' (or', ' may', ' not', ') ha...             [43]   \n1  ['RT', ' @Coach_Brod', ': If', ' you', ' have'...              [2]   \n2  ['#Pharmacists', ' warn', ' against', ' #malar...              [0]   \n3  ['You', ' got', ' to', ' boil', ' your', ' Clo...          [0, 22]   \n4  ['There', ' is', ' no', ' virus', '. \\nAnd', '...              [0]   \n\n  span_end_index  \n0           [53]  \n1           [17]  \n2            [4]  \n3       [20, 33]  \n4            [3]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>span_start_index</th>\n      <th>span_end_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['\"who', ' may', ' (or', ' may', ' not', ') ha...</td>\n      <td>[43]</td>\n      <td>[53]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>['RT', ' @Coach_Brod', ': If', ' you', ' have'...</td>\n      <td>[2]</td>\n      <td>[17]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>['#Pharmacists', ' warn', ' against', ' #malar...</td>\n      <td>[0]</td>\n      <td>[4]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>['You', ' got', ' to', ' boil', ' your', ' Clo...</td>\n      <td>[0, 22]</td>\n      <td>[20, 33]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>['There', ' is', ' no', ' virus', '. \\nAnd', '...</td>\n      <td>[0]</td>\n      <td>[3]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nimport string\n\n# Initialize the WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\n\n# Define your function to process a word\ndef process_word(word):\n    # Remove punctuation\n    word = word.translate(str.maketrans('', '', string.punctuation))\n    # Lemmatize the word\n    word = lemmatizer.lemmatize(word)\n    return word\n\n#convert strings to lists\ndef process_row(row):\n    row['tokens'] = eval(row['tokens'])\n    row['span_start_index'] = eval(row['span_start_index'])\n    row['span_end_index'] = eval(row['span_end_index'])\n    row['tokens'] = [process_word(word) for word in row['tokens']]\n    return row\n\ndf_train2 = df_train2.apply(process_row, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:22:12.334573Z","iopub.execute_input":"2024-03-17T10:22:12.335326Z","iopub.status.idle":"2024-03-17T10:22:15.047505Z","shell.execute_reply.started":"2024-03-17T10:22:12.335294Z","shell.execute_reply":"2024-03-17T10:22:15.046648Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"df_train2.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:22:15.049516Z","iopub.execute_input":"2024-03-17T10:22:15.049813Z","iopub.status.idle":"2024-03-17T10:22:15.067521Z","shell.execute_reply.started":"2024-03-17T10:22:15.049786Z","shell.execute_reply":"2024-03-17T10:22:15.066607Z"},"trusted":true},"execution_count":153,"outputs":[{"execution_count":153,"output_type":"execute_result","data":{"text/plain":"                                              tokens span_start_index  \\\n0  [who,  may,  or,  may,  not,  have,  it,   Sch...             [43]   \n1  [RT,  CoachBrod,  If,  you,  have,  ever,  suc...              [2]   \n2  [Pharmacists,  warn,  against,  malarial,  dru...              [0]   \n3  [You,  got,  to,  boil,  your,  Clorox,  to,  ...          [0, 22]   \n4  [There,  is,  no,  virus,  \\nAnd,  if,  there,...              [0]   \n\n  span_end_index  \n0           [53]  \n1           [17]  \n2            [4]  \n3       [20, 33]  \n4            [3]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>span_start_index</th>\n      <th>span_end_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[who,  may,  or,  may,  not,  have,  it,   Sch...</td>\n      <td>[43]</td>\n      <td>[53]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[RT,  CoachBrod,  If,  you,  have,  ever,  suc...</td>\n      <td>[2]</td>\n      <td>[17]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[Pharmacists,  warn,  against,  malarial,  dru...</td>\n      <td>[0]</td>\n      <td>[4]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[You,  got,  to,  boil,  your,  Clorox,  to,  ...</td>\n      <td>[0, 22]</td>\n      <td>[20, 33]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[There,  is,  no,  virus,  \\nAnd,  if,  there,...</td>\n      <td>[0]</td>\n      <td>[3]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train2.describe()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:22:15.068485Z","iopub.execute_input":"2024-03-17T10:22:15.068747Z","iopub.status.idle":"2024-03-17T10:22:16.588956Z","shell.execute_reply.started":"2024-03-17T10:22:15.068721Z","shell.execute_reply":"2024-03-17T10:22:16.587867Z"},"trusted":true},"execution_count":154,"outputs":[{"execution_count":154,"output_type":"execute_result","data":{"text/plain":"                                                   tokens span_start_index  \\\ncount                                                6044             6044   \nunique                                               6029              688   \ntop     [Lysol,  and,  Dettol,  manufacturer,  tells, ...              [0]   \nfreq                                                    3             1455   \n\n       span_end_index  \ncount            6044  \nunique            833  \ntop               [9]  \nfreq              288  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>span_start_index</th>\n      <th>span_end_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6044</td>\n      <td>6044</td>\n      <td>6044</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>6029</td>\n      <td>688</td>\n      <td>833</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>[Lysol,  and,  Dettol,  manufacturer,  tells, ...</td>\n      <td>[0]</td>\n      <td>[9]</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>3</td>\n      <td>1455</td>\n      <td>288</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Embedding\n\nX_train = df_train2['tokens']\n\n# Calculate vocabulary size\nvocab = set()\nfor tokens in X_train:\n    vocab.update(tokens)\nvocab_size = len(vocab)\nprint(\"Vocabulary size:\", vocab_size)\n\n# Define a function to generate binary labels for each word\ndef generate_binary_labels(tokens, span_start_index, span_end_index):\n    if not span_start_index:  # Check if span_start_index is empty\n        return [0] * len(tokens)  # Return a list of zeros if it is empty\n    binary_labels = []\n    for i, token in enumerate(tokens):\n        if i in range(span_start_index[0], span_end_index[0] + 1):\n            binary_labels.append(1)  # Word is part of the segment\n        else:\n            binary_labels.append(0)  # Word is not part of the segment\n    return binary_labels\n\n# Generate binary labels for each sample\ny_train = [generate_binary_labels(tokens, start_idx, end_idx) for tokens, start_idx, end_idx in zip(df_train2['tokens'], df_train2['span_start_index'], df_train2['span_end_index'])]","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:22:16.590986Z","iopub.execute_input":"2024-03-17T10:22:16.591295Z","iopub.status.idle":"2024-03-17T10:22:16.723996Z","shell.execute_reply.started":"2024-03-17T10:22:16.591268Z","shell.execute_reply":"2024-03-17T10:22:16.723093Z"},"trusted":true},"execution_count":155,"outputs":[{"name":"stdout","text":"Vocabulary size: 26950\n","output_type":"stream"}]},{"cell_type":"code","source":"max_seq_len = max(len(tokens) for tokens in df_train2['tokens'])\n\n# Generate binary labels for each sample and pad sequences\ny_train = []\nfor tokens, start_idx, end_idx in zip(df_train2['tokens'], df_train2['span_start_index'], df_train2['span_end_index']):\n    binary_labels = generate_binary_labels(tokens, start_idx, end_idx)\n    # Pad sequences if necessary\n    if len(binary_labels) < max_seq_len:\n        binary_labels += [0] * (max_seq_len - len(binary_labels))\n    elif len(binary_labels) > max_seq_len:\n        binary_labels = binary_labels[:max_seq_len]\n    y_train.append(binary_labels)\n\ny_train = np.array(y_train)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:22:16.725196Z","iopub.execute_input":"2024-03-17T10:22:16.725589Z","iopub.status.idle":"2024-03-17T10:22:16.899004Z","shell.execute_reply.started":"2024-03-17T10:22:16.725556Z","shell.execute_reply":"2024-03-17T10:22:16.898243Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"# Convert set vocab to list and sort it\nvocab_list = sorted(list(vocab))\n\n# Create a dictionary to map tokens to indices\ntoken_to_index = {token: index for index, token in enumerate(vocab_list)}\n\n# Calculate vocabulary size\nvocab_size = len(vocab_list)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:22:16.900279Z","iopub.execute_input":"2024-03-17T10:22:16.900542Z","iopub.status.idle":"2024-03-17T10:22:16.933078Z","shell.execute_reply.started":"2024-03-17T10:22:16.900520Z","shell.execute_reply":"2024-03-17T10:22:16.932082Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\n\n# Convert tokens to sequences\nX_train_sequences = [[token_to_index[token] for token in tokens] for tokens in df_train2['tokens']]\n\n# Pad sequences\nX_train_padded = pad_sequences(X_train_sequences, maxlen=max_seq_len, padding='post', truncating='post')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:22:16.934398Z","iopub.execute_input":"2024-03-17T10:22:16.934684Z","iopub.status.idle":"2024-03-17T10:22:17.008135Z","shell.execute_reply.started":"2024-03-17T10:22:16.934658Z","shell.execute_reply":"2024-03-17T10:22:17.007379Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"type(X_train_padded)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:22:17.009249Z","iopub.execute_input":"2024-03-17T10:22:17.009592Z","iopub.status.idle":"2024-03-17T10:22:17.015321Z","shell.execute_reply.started":"2024-03-17T10:22:17.009556Z","shell.execute_reply":"2024-03-17T10:22:17.014326Z"},"trusted":true},"execution_count":159,"outputs":[{"execution_count":159,"output_type":"execute_result","data":{"text/plain":"numpy.ndarray"},"metadata":{}}]},{"cell_type":"code","source":"# Define the model architecture\nembedding_dim = 128  # Adjust as needed\nlstm_units = 64  # Adjust as needed\n\nlstm_model2 = Sequential([\n    Embedding(input_dim=vocab_size, output_dim=embedding_dim),  # None allows variable sequence lengths\n    LSTM(units=lstm_units, activation='tanh', return_sequences=True),\n    Dense(units=1, activation='sigmoid')\n])\n\n# Compile the model\nlstm_model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model\nlstm_model2.fit(X_train_padded, y_train, epochs=10, batch_size=32, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:22:17.016605Z","iopub.execute_input":"2024-03-17T10:22:17.017031Z","iopub.status.idle":"2024-03-17T10:22:31.343263Z","shell.execute_reply.started":"2024-03-17T10:22:17.017002Z","shell.execute_reply":"2024-03-17T10:22:31.342372Z"},"trusted":true},"execution_count":160,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8553 - loss: 0.2442 - val_accuracy: 0.9118 - val_loss: 0.1700\nEpoch 2/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9279 - loss: 0.1508 - val_accuracy: 0.9152 - val_loss: 0.1678\nEpoch 3/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9527 - loss: 0.1083 - val_accuracy: 0.9125 - val_loss: 0.1844\nEpoch 4/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9684 - loss: 0.0773 - val_accuracy: 0.9125 - val_loss: 0.2153\nEpoch 5/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9747 - loss: 0.0624 - val_accuracy: 0.9135 - val_loss: 0.2315\nEpoch 6/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9797 - loss: 0.0512 - val_accuracy: 0.9113 - val_loss: 0.2663\nEpoch 7/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9830 - loss: 0.0433 - val_accuracy: 0.9125 - val_loss: 0.2929\nEpoch 8/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9860 - loss: 0.0358 - val_accuracy: 0.9123 - val_loss: 0.3147\nEpoch 9/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9886 - loss: 0.0297 - val_accuracy: 0.9122 - val_loss: 0.3248\nEpoch 10/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9895 - loss: 0.0276 - val_accuracy: 0.9133 - val_loss: 0.3582\n","output_type":"stream"},{"execution_count":160,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7822a44bde40>"},"metadata":{}}]},{"cell_type":"code","source":"import gensim.downloader as api\n\n# Download the pre-trained GloVe word vectors\nglove_vectors = api.load(\"glove-wiki-gigaword-100\")","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:51:05.227137Z","iopub.execute_input":"2024-03-17T10:51:05.227880Z","iopub.status.idle":"2024-03-17T10:51:49.684002Z","shell.execute_reply.started":"2024-03-17T10:51:05.227850Z","shell.execute_reply":"2024-03-17T10:51:49.683105Z"},"trusted":true},"execution_count":207,"outputs":[]},{"cell_type":"code","source":"from keras.initializers import Constant\n\n# Initialize an embedding matrix with zeros\nembedding_matrix = np.zeros((vocab_size, 100))\n\n# Fill the embedding matrix with word vectors from GloVe\nfor word, i in tokenizer.word_index.items():\n    if word in glove_vectors:\n        embedding_matrix[i] = glove_vectors[word]\n\n# Define the model architecture with pre-trained GloVe embeddings\nlstm_model_with_glove = Sequential([\n    Embedding(input_dim=vocab_size, output_dim=100, embeddings_initializer=Constant(embedding_matrix), trainable=False),  \n    LSTM(units=lstm_units, activation='tanh', return_sequences=True),\n    Dense(units=1, activation='sigmoid')\n])\n\n# Compile the model\nlstm_model_with_glove.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model\nlstm_model_with_glove.fit(X_train_padded, y_train, epochs=10, batch_size=32, validation_split=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:53:47.754670Z","iopub.execute_input":"2024-03-17T10:53:47.755543Z","iopub.status.idle":"2024-03-17T10:54:02.185574Z","shell.execute_reply.started":"2024-03-17T10:53:47.755507Z","shell.execute_reply":"2024-03-17T10:54:02.184690Z"},"trusted":true},"execution_count":211,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8764 - loss: 0.2436 - val_accuracy: 0.9048 - val_loss: 0.1758\nEpoch 2/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9226 - loss: 0.1560 - val_accuracy: 0.9123 - val_loss: 0.1700\nEpoch 3/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9452 - loss: 0.1199 - val_accuracy: 0.9109 - val_loss: 0.1819\nEpoch 4/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9627 - loss: 0.0886 - val_accuracy: 0.9108 - val_loss: 0.2052\nEpoch 5/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9719 - loss: 0.0683 - val_accuracy: 0.9121 - val_loss: 0.2355\nEpoch 6/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9783 - loss: 0.0544 - val_accuracy: 0.9120 - val_loss: 0.2666\nEpoch 7/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9824 - loss: 0.0443 - val_accuracy: 0.9119 - val_loss: 0.3008\nEpoch 8/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9855 - loss: 0.0377 - val_accuracy: 0.9120 - val_loss: 0.3296\nEpoch 9/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9872 - loss: 0.0334 - val_accuracy: 0.9127 - val_loss: 0.3511\nEpoch 10/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0314 - val_accuracy: 0.9140 - val_loss: 0.3399\n","output_type":"stream"},{"execution_count":211,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x78229906f7f0>"},"metadata":{}}]},{"cell_type":"code","source":"from keras.layers import Dropout, Bidirectional, GlobalMaxPooling1D","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:06:15.947488Z","iopub.execute_input":"2024-03-17T11:06:15.948204Z","iopub.status.idle":"2024-03-17T11:06:15.952639Z","shell.execute_reply.started":"2024-03-17T11:06:15.948152Z","shell.execute_reply":"2024-03-17T11:06:15.951540Z"},"trusted":true},"execution_count":233,"outputs":[]},{"cell_type":"code","source":"# Define the model architecture with additional layers\nlstm_model_with_dropout = Sequential([\n    Embedding(input_dim=vocab_size, output_dim=embedding_dim),  \n    LSTM(units=lstm_units, activation='tanh', return_sequences=True),\n    Dropout(0.2),  # Dropout layer to prevent overfitting\n    Bidirectional(LSTM(units=lstm_units, activation='tanh', return_sequences=True)),  # Bidirectional LSTM layer for better context understanding\n    Dropout(0.2),  # Dropout layer\n    Dense(units=64, activation='relu'),  # Additional Dense layer for more complex mappings\n    Dropout(0.2),  # Dropout layer\n    Dense(units=1, activation='sigmoid')\n])\n\n# Compile the model\nlstm_model_with_dropout.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model\nlstm_model_with_dropout.fit(X_train_padded, y_train, epochs=10, batch_size=32, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:07:06.211033Z","iopub.execute_input":"2024-03-17T11:07:06.211957Z","iopub.status.idle":"2024-03-17T11:07:12.692810Z","shell.execute_reply.started":"2024-03-17T11:07:06.211920Z","shell.execute_reply":"2024-03-17T11:07:12.691394Z"},"trusted":true},"execution_count":235,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m149/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8573 - loss: 0.2650","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[235], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m lstm_model_with_dropout\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mlstm_model_with_dropout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m         value \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    114\u001b[0m             format_argument_value,\n\u001b[1;32m    115\u001b[0m             bound_signature\u001b[38;5;241m.\u001b[39marguments[arg\u001b[38;5;241m.\u001b[39mname],\n\u001b[1;32m    116\u001b[0m         )\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         value \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mdefault\n\u001b[1;32m    119\u001b[0m     arguments_context\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  • \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arguments_context:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:349\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m         value \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    114\u001b[0m             format_argument_value,\n\u001b[1;32m    115\u001b[0m             bound_signature\u001b[38;5;241m.\u001b[39marguments[arg\u001b[38;5;241m.\u001b[39mname],\n\u001b[1;32m    116\u001b[0m         )\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         value \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mdefault\n\u001b[1;32m    119\u001b[0m     arguments_context\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  • \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arguments_context:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:435\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\n\n# Define the model architecture with regularization\nlstm_model_with_regularization = Sequential([\n    Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n    Bidirectional(LSTM(units=lstm_units, activation='tanh', return_sequences=True)),\n    Dense(units=64, activation='relu', kernel_regularizer=l2(0.01)),  # Adding L2 regularization\n    Dropout(0.5),  # Dropout for regularization\n    Dense(units=32, activation='relu', kernel_regularizer=l2(0.01)),  # Adding L2 regularization\n    Dropout(0.5),  # Dropout for regularization\n    Dense(units=1, activation='sigmoid')\n])\n\n# Compile the model\nlstm_model_with_regularization.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Define checkpoint callback to save the best model\ncheckpoint = ModelCheckpoint(\"best_lstm_model_with_regularization.keras\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\n# Train the model with checkpoint callback\nhistory = lstm_model_with_regularization.fit(X_train_padded, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[checkpoint])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:12:35.006171Z","iopub.execute_input":"2024-03-17T11:12:35.007060Z","iopub.status.idle":"2024-03-17T11:12:58.613606Z","shell.execute_reply.started":"2024-03-17T11:12:35.007024Z","shell.execute_reply":"2024-03-17T11:12:58.612685Z"},"trusted":true},"execution_count":245,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m151/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8448 - loss: 1.1311\nEpoch 1: val_accuracy improved from -inf to 0.90880, saving model to best_lstm_model_with_regularization.keras\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.8452 - loss: 1.1261 - val_accuracy: 0.9088 - val_loss: 0.3089\nEpoch 2/10\n\u001b[1m151/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9154 - loss: 0.2593\nEpoch 2: val_accuracy improved from 0.90880 to 0.92040, saving model to best_lstm_model_with_regularization.keras\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9154 - loss: 0.2589 - val_accuracy: 0.9204 - val_loss: 0.2108\nEpoch 3/10\n\u001b[1m151/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9471 - loss: 0.1522\nEpoch 3: val_accuracy improved from 0.92040 to 0.92300, saving model to best_lstm_model_with_regularization.keras\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9471 - loss: 0.1522 - val_accuracy: 0.9230 - val_loss: 0.1845\nEpoch 4/10\n\u001b[1m149/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9650 - loss: 0.1137\nEpoch 4: val_accuracy improved from 0.92300 to 0.92305, saving model to best_lstm_model_with_regularization.keras\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9650 - loss: 0.1136 - val_accuracy: 0.9230 - val_loss: 0.2104\nEpoch 5/10\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9764 - loss: 0.0865\nEpoch 5: val_accuracy improved from 0.92305 to 0.92321, saving model to best_lstm_model_with_regularization.keras\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9763 - loss: 0.0865 - val_accuracy: 0.9232 - val_loss: 0.2187\nEpoch 6/10\n\u001b[1m151/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9835 - loss: 0.0683\nEpoch 6: val_accuracy did not improve from 0.92321\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9835 - loss: 0.0683 - val_accuracy: 0.9232 - val_loss: 0.2509\nEpoch 7/10\n\u001b[1m151/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9872 - loss: 0.0576\nEpoch 7: val_accuracy did not improve from 0.92321\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9872 - loss: 0.0576 - val_accuracy: 0.9225 - val_loss: 0.2582\nEpoch 8/10\n\u001b[1m151/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9902 - loss: 0.0484\nEpoch 8: val_accuracy did not improve from 0.92321\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9902 - loss: 0.0484 - val_accuracy: 0.9225 - val_loss: 0.2770\nEpoch 9/10\n\u001b[1m150/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9915 - loss: 0.0437\nEpoch 9: val_accuracy did not improve from 0.92321\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9915 - loss: 0.0437 - val_accuracy: 0.9217 - val_loss: 0.2830\nEpoch 10/10\n\u001b[1m148/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9924 - loss: 0.0408\nEpoch 10: val_accuracy did not improve from 0.92321\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9924 - loss: 0.0408 - val_accuracy: 0.9217 - val_loss: 0.3009\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.models import load_model\n\n# Load the best model\nlstm_model_with_regularization.save(\"best_lstm_model_with_regularization.keras\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:13:59.942958Z","iopub.execute_input":"2024-03-17T11:13:59.943692Z","iopub.status.idle":"2024-03-17T11:14:00.199528Z","shell.execute_reply.started":"2024-03-17T11:13:59.943643Z","shell.execute_reply":"2024-03-17T11:14:00.198395Z"},"trusted":true},"execution_count":249,"outputs":[]},{"cell_type":"code","source":"df_val2 = pd.read_csv('/kaggle/input/ai-for-social-good-aries-iitd-x-kaizen-24/Public/Task 2/dev.csv')\ndf_val2.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:22:31.347288Z","iopub.execute_input":"2024-03-17T10:22:31.347622Z","iopub.status.idle":"2024-03-17T10:22:31.366315Z","shell.execute_reply.started":"2024-03-17T10:22:31.347597Z","shell.execute_reply":"2024-03-17T10:22:31.365270Z"},"trusted":true},"execution_count":161,"outputs":[{"execution_count":161,"output_type":"execute_result","data":{"text/plain":"                                              tokens span_start_index  \\\n0  ['attempt', ' by', ' to', ' minimize', ' coron...             [11]   \n1  ['I', ' do', ' not', ' defend', ' Trump', ' mu...             [15]   \n2  ['truly', ' sobering', ' analysis', ' us', ' m...              [3]   \n3  ['Bombshell', ': Chinese', ' Doctor', ' Experi...              [1]   \n4  ['Now', ' I', ' get', ' it', ' from', ' #Fauci...          [7, 10]   \n\n  span_end_index  \n0           [23]  \n1           [25]  \n2           [10]  \n3           [12]  \n4        [9, 20]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>span_start_index</th>\n      <th>span_end_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['attempt', ' by', ' to', ' minimize', ' coron...</td>\n      <td>[11]</td>\n      <td>[23]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>['I', ' do', ' not', ' defend', ' Trump', ' mu...</td>\n      <td>[15]</td>\n      <td>[25]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>['truly', ' sobering', ' analysis', ' us', ' m...</td>\n      <td>[3]</td>\n      <td>[10]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>['Bombshell', ': Chinese', ' Doctor', ' Experi...</td>\n      <td>[1]</td>\n      <td>[12]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>['Now', ' I', ' get', ' it', ' from', ' #Fauci...</td>\n      <td>[7, 10]</td>\n      <td>[9, 20]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_val2 = df_val2.apply(process_row, axis = 1)\ndf_val2.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:22:31.367618Z","iopub.execute_input":"2024-03-17T10:22:31.368012Z","iopub.status.idle":"2024-03-17T10:22:31.745969Z","shell.execute_reply.started":"2024-03-17T10:22:31.367975Z","shell.execute_reply":"2024-03-17T10:22:31.744887Z"},"trusted":true},"execution_count":162,"outputs":[{"execution_count":162,"output_type":"execute_result","data":{"text/plain":"                                              tokens span_start_index  \\\n0  [attempt,  by,  to,  minimize,  coronavirus,  ...             [11]   \n1  [I,  do,  not,  defend,  Trump,  much,  but,  ...             [15]   \n2  [truly,  sobering,  analysis,  us,  more,  vul...              [3]   \n3  [Bombshell,  Chinese,  Doctor,  Experimented, ...              [1]   \n4  [Now,  I,  get,  it,  from,  Fauci,  COVID19, ...          [7, 10]   \n\n  span_end_index  \n0           [23]  \n1           [25]  \n2           [10]  \n3           [12]  \n4        [9, 20]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>span_start_index</th>\n      <th>span_end_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[attempt,  by,  to,  minimize,  coronavirus,  ...</td>\n      <td>[11]</td>\n      <td>[23]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[I,  do,  not,  defend,  Trump,  much,  but,  ...</td>\n      <td>[15]</td>\n      <td>[25]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[truly,  sobering,  analysis,  us,  more,  vul...</td>\n      <td>[3]</td>\n      <td>[10]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[Bombshell,  Chinese,  Doctor,  Experimented, ...</td>\n      <td>[1]</td>\n      <td>[12]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[Now,  I,  get,  it,  from,  Fauci,  COVID19, ...</td>\n      <td>[7, 10]</td>\n      <td>[9, 20]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"UNK_TOKEN_INDEX = len(vocab_list)  # Assuming it's the next index after the vocabulary size\n\n# Convert tokens to sequences, replacing out-of-vocabulary tokens with UNK_TOKEN_INDEX\nX_val_sequences = [[token_to_index.get(token, UNK_TOKEN_INDEX) for token in tokens] for tokens in df_val2['tokens']]","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:22:31.747475Z","iopub.execute_input":"2024-03-17T10:22:31.747917Z","iopub.status.idle":"2024-03-17T10:22:31.763094Z","shell.execute_reply.started":"2024-03-17T10:22:31.747877Z","shell.execute_reply":"2024-03-17T10:22:31.762082Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"max_val_len = max(len(sequence) for sequence in X_val_sequences)\nX_val_padded = pad_sequences(X_val_sequences, maxlen=max_val_len, padding='post', truncating='post')","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:22:31.764503Z","iopub.execute_input":"2024-03-17T10:22:31.764964Z","iopub.status.idle":"2024-03-17T10:22:31.779551Z","shell.execute_reply.started":"2024-03-17T10:22:31.764931Z","shell.execute_reply":"2024-03-17T10:22:31.778558Z"},"trusted":true},"execution_count":164,"outputs":[]},{"cell_type":"code","source":"y_val = [generate_binary_labels(tokens, start_idx, end_idx) for tokens, start_idx, end_idx in zip(df_val2['tokens'], df_val2['span_start_index'], df_val2['span_end_index'])]\n\n# Generate binary labels for each sample and pad sequences\ny_val = []\nfor tokens, start_idx, end_idx in zip(df_val2['tokens'], df_val2['span_start_index'], df_val2['span_end_index']):\n    binary_labels = generate_binary_labels(tokens, start_idx, end_idx)\n    # Pad sequences if necessary\n    if len(binary_labels) < max_val_len:\n        binary_labels += [0] * (max_val_len - len(binary_labels))\n    elif len(binary_labels) > max_val_len:\n        binary_labels = binary_labels[:max_val_len]\n    y_val.append(binary_labels)\n\ny_val = np.array(y_val)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:22:31.780818Z","iopub.execute_input":"2024-03-17T10:22:31.781110Z","iopub.status.idle":"2024-03-17T10:22:31.823310Z","shell.execute_reply.started":"2024-03-17T10:22:31.781085Z","shell.execute_reply":"2024-03-17T10:22:31.822270Z"},"trusted":true},"execution_count":165,"outputs":[]},{"cell_type":"code","source":"X_val_padded.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:22:31.824445Z","iopub.execute_input":"2024-03-17T10:22:31.824735Z","iopub.status.idle":"2024-03-17T10:22:31.830636Z","shell.execute_reply.started":"2024-03-17T10:22:31.824711Z","shell.execute_reply":"2024-03-17T10:22:31.829703Z"},"trusted":true},"execution_count":166,"outputs":[{"execution_count":166,"output_type":"execute_result","data":{"text/plain":"(756, 59)"},"metadata":{}}]},{"cell_type":"code","source":"y_val.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:22:31.831801Z","iopub.execute_input":"2024-03-17T10:22:31.832317Z","iopub.status.idle":"2024-03-17T10:22:31.841175Z","shell.execute_reply.started":"2024-03-17T10:22:31.832285Z","shell.execute_reply":"2024-03-17T10:22:31.840294Z"},"trusted":true},"execution_count":167,"outputs":[{"execution_count":167,"output_type":"execute_result","data":{"text/plain":"(756, 59)"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate the model on validation data\n#val_loss, val_accuracy = lstm_model2.evaluate(X_val_padded, y_val)\nval_loss, val_accuracy = lstm_model_with_dropout.evaluate(X_val_padded, y_val)\n# Print validation loss and accuracy\nprint(\"Validation Loss:\", val_loss)\nprint(\"Validation Accuracy:\", val_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:02:57.319621Z","iopub.execute_input":"2024-03-17T11:02:57.320731Z","iopub.status.idle":"2024-03-17T11:02:58.981195Z","shell.execute_reply.started":"2024-03-17T11:02:57.320688Z","shell.execute_reply":"2024-03-17T11:02:58.980376Z"},"trusted":true},"execution_count":230,"outputs":[{"name":"stdout","text":"\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8822 - loss: 0.5125\nValidation Loss: 0.5358427166938782\nValidation Accuracy: 0.8800331354141235\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Testing : Task 2","metadata":{}},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:55:14.768267Z","iopub.execute_input":"2024-03-17T10:55:14.768672Z","iopub.status.idle":"2024-03-17T10:55:14.781298Z","shell.execute_reply.started":"2024-03-17T10:55:14.768641Z","shell.execute_reply":"2024-03-17T10:55:14.780244Z"},"trusted":true},"execution_count":215,"outputs":[{"execution_count":215,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0  ID                                               text  claim  \\\n0           0   0  Of course we should have captured Osama Bin La...      1   \n1           1   1  covid19 will end soon amen covid19 will end so...      0   \n2           2   2  #Coronavirus #SanDiego #1 #Hotspot #92103 # Co...      1   \n3           3   3  @ICannot_Enough @elonmusk Yes it is. Because $...      0   \n4           4   4  Some people are saying black people are immune...      1   \n\n  span_start_index span_end_index  task  \n0             [-2]           [-2]     1  \n1             [-2]           [-2]     1  \n2             [-2]           [-2]     1  \n3             [-2]           [-2]     1  \n4             [-2]           [-2]     1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>ID</th>\n      <th>text</th>\n      <th>claim</th>\n      <th>span_start_index</th>\n      <th>span_end_index</th>\n      <th>task</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>Of course we should have captured Osama Bin La...</td>\n      <td>1</td>\n      <td>[-2]</td>\n      <td>[-2]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>covid19 will end soon amen covid19 will end so...</td>\n      <td>0</td>\n      <td>[-2]</td>\n      <td>[-2]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>#Coronavirus #SanDiego #1 #Hotspot #92103 # Co...</td>\n      <td>1</td>\n      <td>[-2]</td>\n      <td>[-2]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>@ICannot_Enough @elonmusk Yes it is. Because $...</td>\n      <td>0</td>\n      <td>[-2]</td>\n      <td>[-2]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>Some people are saying black people are immune...</td>\n      <td>1</td>\n      <td>[-2]</td>\n      <td>[-2]</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test2 = df_test[df_test['task'] == 2]\n\nX_test_sequences2 = [[token_to_index.get(token, UNK_TOKEN_INDEX) for token in tokens] for tokens in df_test2['text']]\nmax_test_len = max(len(sequence) for sequence in X_test_sequences2)\n# Pad sequences\nX_test_padded2 = pad_sequences(X_test_sequences2, maxlen=max_test_len, padding='post', truncating='post')\n\nX_test_padded2 = pad_sequences(X_test_sequences2, maxlen=max_test_len, padding='post', truncating='post')","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:55:16.862770Z","iopub.execute_input":"2024-03-17T10:55:16.863457Z","iopub.status.idle":"2024-03-17T10:55:16.941551Z","shell.execute_reply.started":"2024-03-17T10:55:16.863423Z","shell.execute_reply":"2024-03-17T10:55:16.940769Z"},"trusted":true},"execution_count":216,"outputs":[]},{"cell_type":"code","source":"# Use the model to predict on the test data\n#predictions = lstm_model2.predict(X_test_padded2)\n#predictions = lstm_model_with_glove.predict(X_test_padded2)\npredictions = lstm_model_with_regularization.predict(X_test_padded2)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:14:23.859029Z","iopub.execute_input":"2024-03-17T11:14:23.859941Z","iopub.status.idle":"2024-03-17T11:14:24.756183Z","shell.execute_reply.started":"2024-03-17T11:14:23.859907Z","shell.execute_reply":"2024-03-17T11:14:24.755208Z"},"trusted":true},"execution_count":250,"outputs":[{"name":"stdout","text":"\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert predicted probabilities to binary values\nbinary_predictions = (predictions > 0.5).astype(int)\n# Define a function to convert binary predictions to span segments\ndef binary_to_spans(binary_predictions):\n    span_start_index = []\n    span_end_index = []\n    for prediction_row in binary_predictions:\n        start = None\n        start_inds = []\n        end_inds = []\n        \n        for i, pred in enumerate(prediction_row):\n            if pred == [1]:\n                if start is None:\n                    start = i\n                    start_inds.append(i)\n            else:\n                if start is None:\n                    continue\n                else:\n                    end_inds.append(i-1)\n                    start = None\n        if start is not None:\n            end_inds.append(len(prediction_row) - 1)\n        span_start_index.append(start_inds)\n        span_end_index.append(end_inds)\n    return span_start_index, span_end_index\n\n# Convert binary predictions to span segments\nspan_start_index, span_end_index = binary_to_spans(binary_predictions)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:14:25.935542Z","iopub.execute_input":"2024-03-17T11:14:25.936506Z","iopub.status.idle":"2024-03-17T11:14:27.580113Z","shell.execute_reply.started":"2024-03-17T11:14:25.936469Z","shell.execute_reply":"2024-03-17T11:14:27.579202Z"},"trusted":true},"execution_count":251,"outputs":[]},{"cell_type":"code","source":"# Find the indices of rows where task is equal to 2\ntask_2_indices = df_test[df_test['task'] == 2].index\n\n# Update the span columns in df_test for rows where task is equal to 2\nfor i, idx in enumerate(task_2_indices):\n    df_test.at[idx, 'span_start_index'] = span_start_index[i]\n    df_test.at[idx, 'span_end_index'] = span_end_index[i]","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:14:27.581903Z","iopub.execute_input":"2024-03-17T11:14:27.582254Z","iopub.status.idle":"2024-03-17T11:14:27.624788Z","shell.execute_reply.started":"2024-03-17T11:14:27.582226Z","shell.execute_reply":"2024-03-17T11:14:27.623781Z"},"trusted":true},"execution_count":252,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:14:27.625972Z","iopub.execute_input":"2024-03-17T11:14:27.626281Z","iopub.status.idle":"2024-03-17T11:14:27.644196Z","shell.execute_reply.started":"2024-03-17T11:14:27.626256Z","shell.execute_reply":"2024-03-17T11:14:27.643206Z"},"trusted":true},"execution_count":253,"outputs":[{"execution_count":253,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0  ID                                               text  claim  \\\n0           0   0  Of course we should have captured Osama Bin La...      1   \n1           1   1  covid19 will end soon amen covid19 will end so...      0   \n2           2   2  #Coronavirus #SanDiego #1 #Hotspot #92103 # Co...      1   \n3           3   3  @ICannot_Enough @elonmusk Yes it is. Because $...      0   \n4           4   4  Some people are saying black people are immune...      1   \n\n  span_start_index span_end_index  task  \n0             [-2]           [-2]     1  \n1             [-2]           [-2]     1  \n2             [-2]           [-2]     1  \n3             [-2]           [-2]     1  \n4             [-2]           [-2]     1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>ID</th>\n      <th>text</th>\n      <th>claim</th>\n      <th>span_start_index</th>\n      <th>span_end_index</th>\n      <th>task</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>Of course we should have captured Osama Bin La...</td>\n      <td>1</td>\n      <td>[-2]</td>\n      <td>[-2]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>covid19 will end soon amen covid19 will end so...</td>\n      <td>0</td>\n      <td>[-2]</td>\n      <td>[-2]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>#Coronavirus #SanDiego #1 #Hotspot #92103 # Co...</td>\n      <td>1</td>\n      <td>[-2]</td>\n      <td>[-2]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>@ICannot_Enough @elonmusk Yes it is. Because $...</td>\n      <td>0</td>\n      <td>[-2]</td>\n      <td>[-2]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>Some people are saying black people are immune...</td>\n      <td>1</td>\n      <td>[-2]</td>\n      <td>[-2]</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test.iloc[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:14:29.357269Z","iopub.execute_input":"2024-03-17T11:14:29.357917Z","iopub.status.idle":"2024-03-17T11:14:29.365478Z","shell.execute_reply.started":"2024-03-17T11:14:29.357885Z","shell.execute_reply":"2024-03-17T11:14:29.364395Z"},"trusted":true},"execution_count":254,"outputs":[{"execution_count":254,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0                                                          0\nID                                                                  0\ntext                Of course we should have captured Osama Bin La...\nclaim                                                               1\nspan_start_index                                                 [-2]\nspan_end_index                                                   [-2]\ntask                                                                1\nName: 0, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"df_test.to_csv('submission2_1_1_3.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:14:33.589400Z","iopub.execute_input":"2024-03-17T11:14:33.589788Z","iopub.status.idle":"2024-03-17T11:14:33.626387Z","shell.execute_reply.started":"2024-03-17T11:14:33.589758Z","shell.execute_reply":"2024-03-17T11:14:33.625377Z"},"trusted":true},"execution_count":255,"outputs":[]},{"cell_type":"code","source":"lstm_model2.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T11:05:10.567895Z","iopub.execute_input":"2024-03-17T11:05:10.568598Z","iopub.status.idle":"2024-03-17T11:05:10.594836Z","shell.execute_reply.started":"2024-03-17T11:05:10.568563Z","shell.execute_reply":"2024-03-17T11:05:10.593729Z"},"trusted":true},"execution_count":231,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_8\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_9 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m3,449,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │            \u001b[38;5;34m65\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,449,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,497,221\u001b[0m (40.04 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,497,221</span> (40.04 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,499,073\u001b[0m (13.35 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,499,073</span> (13.35 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6,998,148\u001b[0m (26.70 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,998,148</span> (26.70 MB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}